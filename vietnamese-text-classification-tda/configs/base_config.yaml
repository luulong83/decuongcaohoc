# ============================================
# Base Configuration - Vietnamese Text Classification with TDA
# ============================================

# Project metadata
project:
  name: "vietnamese-text-classification-tda"
  version: "1.0.0"
  author: "Luu Cang Kim Long"
  description: "Improving Vietnamese Text Classification via TDA and Data Augmentation"

# Paths
paths:
  data_dir: "data"
  raw_data_dir: "data/raw"
  processed_data_dir: "data/processed"
  augmented_data_dir: "data/augmented"
  cache_dir: "data/cache"
  checkpoint_dir: "experiments/checkpoints"
  log_dir: "experiments/logs"
  results_dir: "experiments/results"
  visualization_dir: "experiments/visualizations"

# Dataset
dataset:
  name: "UIT-VSFC"
  max_length: 256  # Maximum sequence length
  batch_size: 16
  num_workers: 4
  tasks:
    - sentiment  # 3 classes: Positive, Neutral, Negative
    - topic      # 10 classes

# Model
model:
  name: "vinai/phobert-base"
  hidden_size: 768
  num_attention_heads: 12
  num_hidden_layers: 12
  dropout: 0.1
  
  # TDA configuration
  tda:
    enabled: true
    selected_layers: [8, 9, 10, 11]  # Late layers
    homology_dims: [0, 1]  # H₀ and H₁
    max_dimension: 1
    persistence_image:
      resolution: 20  # 20×20 grid
      sigma: 0.1      # Gaussian smoothing
      normalize: true
    feature_dim: 3200  # 4 layers × 2 dims × 400
  
  # Fusion configuration
  fusion:
    method: "concat"  # Options: concat, attention, gated
    hidden_dims: [1024, 512]
    dropout: 0.3

# Data Augmentation
augmentation:
  enabled: true
  ratio: 0.3  # 30% of training data
  techniques:
    synonym_replacement:
      enabled: true
      weight: 0.4  # 40% of augmented data
      replace_ratio: 0.1  # Replace 10% of words
      tone_aware: true
      preserve_compounds: true
    
    back_translation:
      enabled: true
      weight: 0.3  # 30% of augmented data
      source_lang: "vi"
      pivot_lang: "en"
      quality_threshold: 0.7
      max_bleu: 0.95
    
    contextual:
      enabled: true
      weight: 0.3  # 30% of augmented data
      mask_ratio: 0.15
      top_k: 5
      model: "vinai/phobert-base"

# Training
training:
  num_epochs: 20
  learning_rate: 2.0e-5
  weight_decay: 0.01
  warmup_steps: 500
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  
  optimizer:
    type: "AdamW"
    betas: [0.9, 0.999]
    eps: 1.0e-8
  
  scheduler:
    type: "linear"  # Options: linear, cosine, constant
    num_warmup_steps: 500
  
  early_stopping:
    enabled: true
    patience: 3
    min_delta: 0.001
    monitor: "val_f1_macro"
    mode: "max"
  
  checkpoint:
    save_best: true
    save_interval: 1  # Save every epoch
    keep_last_n: 3

# Evaluation
evaluation:
  metrics:
    - accuracy
    - precision
    - recall
    - f1_macro
    - f1_weighted
  
  statistical_tests:
    enabled: true
    paired_ttest:
      alpha: 0.05
    cohens_d:
      threshold: 0.5

# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  console: true
  file: true
  tensorboard: true
  log_interval: 10  # Log every N batches
  
# Computation
computation:
  device: "auto"  # auto, cuda, cpu
  seed: 42
  deterministic: true
  num_gpus: 1
  mixed_precision: true  # Use AMP for faster training
  
# Reproducibility
reproducibility:
  seed: 42
  cudnn_deterministic: true
  cudnn_benchmark: false